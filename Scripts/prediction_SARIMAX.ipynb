{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       MSR_DT STTN_NM  PM25  PM10     O3   CO    SO2    NO2     NO    NOX\n",
      "0  2021010101     명서동  11.0  22.0  0.022  0.5  0.003  0.023  0.009  0.032\n",
      "1  2021010102     명서동  12.0  16.0  0.028  0.4  0.003  0.015  0.007  0.022\n",
      "2  2021010103     명서동  13.0  21.0  0.031  0.4  0.003  0.013  0.006  0.019\n",
      "3  2021010104     명서동  15.0  19.0  0.028  0.4  0.003  0.013  0.006  0.019\n",
      "4  2021010105     명서동  15.0  22.0  0.024  0.4  0.003  0.015  0.006  0.021\n",
      "(1122344, 10)\n"
     ]
    }
   ],
   "source": [
    "# import dataset\n",
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_21 = '/Users/hayden/Desktop/2021년전체측정소자료.csv'\n",
    "file_22 = '/Users/hayden/Desktop/2022년전체측정소자료.csv'\n",
    "file_23 = '/Users/hayden/Desktop/2023년전체측정소자료.csv'\n",
    "\n",
    "# reading each csv file as data frame\n",
    "df_21 = pd.read_csv(file_21)\n",
    "df_22 = pd.read_csv(file_22)\n",
    "df_23 = pd.read_csv(file_23)\n",
    "\n",
    "# list \n",
    "dfs = [df_21, df_22, df_23]\n",
    "\n",
    "# concat\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# print and chenk result\n",
    "print(df.head())  # 합쳐진 데이터프레임의 첫 부분 출력\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6k/r_smdd550yddqpmrhzs0gqyh0000gn/T/ipykernel_71302/960638065.py:8: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df[col] = df[col].interpolate(method='linear', limit_direction='both')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PM25 컬럼의 NULL 값 개수: 0\n",
      "PM10 컬럼의 NULL 값 개수: 0\n",
      "O3 컬럼의 NULL 값 개수: 0\n",
      "CO 컬럼의 NULL 값 개수: 0\n",
      "SO2 컬럼의 NULL 값 개수: 0\n",
      "NO2 컬럼의 NULL 값 개수: 0\n",
      "전체 데이터프레임의 NULL 값 개수: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# interpolate \n",
    "for col in df.columns:\n",
    "    # if df[col].dtype != 'datetime64[ns]':\n",
    "    df[col] = df[col].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "df_copy = df.copy()\n",
    "\n",
    "# count nulls\n",
    "null_counts = df_copy.isnull().sum()\n",
    "\n",
    "# check null count on each columns\n",
    "PM25_null_count = df_copy['PM25'].isnull().sum()\n",
    "PM10_null_count = df_copy['PM10'].isnull().sum()\n",
    "O3_null_count = df_copy['O3'].isnull().sum()\n",
    "CO_null_count = df_copy['CO'].isnull().sum()\n",
    "SO2_null_count = df_copy['SO2'].isnull().sum()\n",
    "NO2_null_count = df_copy['NO2'].isnull().sum()\n",
    "\n",
    "print(\"PM25 컬럼의 NULL 값 개수:\", PM25_null_count)\n",
    "print(\"PM10 컬럼의 NULL 값 개수:\", PM10_null_count)\n",
    "print(\"O3 컬럼의 NULL 값 개수:\", O3_null_count)\n",
    "print(\"CO 컬럼의 NULL 값 개수:\", CO_null_count)\n",
    "print(\"SO2 컬럼의 NULL 값 개수:\", SO2_null_count)\n",
    "print(\"NO2 컬럼의 NULL 값 개수:\", NO2_null_count)\n",
    "\n",
    "# print total null count\n",
    "total_null_count = df_copy.isnull().sum().sum()\n",
    "print(\"전체 데이터프레임의 NULL 값 개수:\", total_null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             MSR_DT  PM25  PM10     O3   CO    SO2    NO2\n",
      "0        2021010101  11.0  22.0  0.022  0.5  0.003  0.023\n",
      "1        2021010102  12.0  16.0  0.028  0.4  0.003  0.015\n",
      "2        2021010103  13.0  21.0  0.031  0.4  0.003  0.013\n",
      "3        2021010104  15.0  19.0  0.028  0.4  0.003  0.013\n",
      "4        2021010105  15.0  22.0  0.024  0.4  0.003  0.015\n",
      "...             ...   ...   ...    ...  ...    ...    ...\n",
      "1117136  2023123120   0.0  11.0  0.037  0.4  0.001  0.013\n",
      "1117137  2023123121  15.0  15.0  0.036  0.4  0.001  0.012\n",
      "1117138  2023123122   0.0  14.0  0.035  0.4  0.001  0.012\n",
      "1117139  2023123123   0.0  11.0  0.032  0.4  0.001  0.014\n",
      "1117140  2023123124   0.0  16.0  0.031  0.4  0.001  0.013\n",
      "\n",
      "[1096258 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df[~df['STTN_NM'].isin(['이동차', '부산항'])]\n",
    "df.drop(columns=['NO', 'NOX', 'STTN_NM'], inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after scaling:\n",
      "       MSR_DT      PM25      PM10        O3        CO       SO2       NO2\n",
      "0  2021010101  0.041237  0.017460  0.100000  0.097656  0.019737  0.212963\n",
      "1  2021010102  0.044674  0.012698  0.127273  0.078125  0.019737  0.138889\n",
      "2  2021010103  0.048110  0.016667  0.140909  0.078125  0.019737  0.120370\n",
      "3  2021010104  0.054983  0.015079  0.127273  0.078125  0.019737  0.120370\n",
      "4  2021010105  0.054983  0.017460  0.109091  0.078125  0.019737  0.138889\n"
     ]
    }
   ],
   "source": [
    "# MinMaxScaler 사용\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['PM25', 'PM10', 'O3', 'CO', 'SO2', 'NO2']\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# 데이터 확인\n",
    "print(\"Data after scaling:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (877006, 4)\n",
      "Shape of X_test: (219252, 4)\n",
      "Shape of y_train: (877006, 2)\n",
      "Shape of y_test: (219252, 2)\n"
     ]
    }
   ],
   "source": [
    "# 타겟 변수 설정 (예시로 PM25와 PM10 예측)\n",
    "target_columns = ['PM25', 'PM10']\n",
    "X = df.drop(columns=target_columns + ['MSR_DT'])  # 예측에 사용될 피처\n",
    "y = df[target_columns]  # 타겟 변수\n",
    "\n",
    "# 80:20으로 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/homebrew/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/homebrew/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n",
      "/opt/homebrew/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/homebrew/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/homebrew/lib/python3.11/site-packages/statsmodels/base/model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         test_PM25  pred_PM25  test_PM10  pred_PM10\n",
      "118080    0.065292        NaN   0.016667        NaN\n",
      "320506    0.030928        NaN   0.009524        NaN\n",
      "1001690   0.171821        NaN   0.100794        NaN\n",
      "40205     0.034418        NaN   0.012717        NaN\n",
      "124805    0.044674        NaN   0.042063        NaN\n"
     ]
    }
   ],
   "source": [
    "# SARIMAX 모델 설정 및 학습\n",
    "# PM25 예측 모델\n",
    "model_pm25 = SARIMAX(y_train['PM25'], exog=X_train, order=(1, 1, 1))\n",
    "results_pm25 = model_pm25.fit(disp=False)\n",
    "\n",
    "# PM10 예측 모델\n",
    "model_pm10 = SARIMAX(y_train['PM10'], exog=X_train, order=(1, 1, 1))\n",
    "results_pm10 = model_pm10.fit(disp=False)\n",
    "\n",
    "# 예측\n",
    "pred_pm25 = results_pm25.get_prediction(exog=X_test).predicted_mean\n",
    "pred_pm10 = results_pm10.get_prediction(exog=X_test).predicted_mean\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 저장\n",
    "test_pred = pd.DataFrame({'test_PM25': y_test['PM25'], 'pred_PM25': pred_pm25,\n",
    "                          'test_PM10': y_test['PM10'], 'pred_PM10': pred_pm10}, index=y_test.index)\n",
    "\n",
    "print(test_pred.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제 설명 및 해석\n",
    "경고 메시지:\n",
    "\n",
    "ValueWarning: An unsupported index was provided and will be ignored when e.g. forecasting.:\n",
    "SARIMAX 모델이 예측할 때 지원되지 않는 인덱스가 제공되었음을 의미합니다. 예측 결과에 인덱스를 무시하고 있습니다.\n",
    "ConvergenceWarning: Maximum Likelihood optimization failed to converge.:\n",
    "최대 우도 최적화가 수렴하지 못했음을 의미합니다. 모델이 최적의 파라미터를 찾지 못했을 수 있습니다.\n",
    "예측 결과:\n",
    "\n",
    "예측 값(pred_PM25, pred_PM10)이 NaN으로 나왔습니다. 이는 모델이 예측을 생성하지 못했다는 것을 의미합니다.\n",
    "원인 분석\n",
    "지원되지 않는 인덱스:\n",
    "\n",
    "X_train 및 X_test 데이터에 시간 인덱스가 포함되어 있지 않거나, 모델이 이를 지원하지 않는 형식으로 인덱스를 제공받았을 가능성이 큽니다.\n",
    "최적화 실패:\n",
    "\n",
    "데이터가 정상적으로 제공되지 않거나, 모델의 설정이 잘못되었을 수 있습니다. 특히, SARIMAX 모델은 시계열 데이터에서 특정 파라미터 설정에 민감할 수 있습니다.\n",
    "해결 방법\n",
    "인덱스 문제 해결:\n",
    "\n",
    "X_train 및 X_test의 인덱스를 올바르게 설정합니다. 시계열 데이터에서 적절한 인덱스를 설정하여 모델이 이를 인식할 수 있도록 합니다.\n",
    "모델 설정 및 데이터 검토:\n",
    "\n",
    "모델의 order 파라미터를 조정하거나 데이터를 다시 검토합니다. 특정 파라미터가 모델의 수렴에 영향을 미칠 수 있습니다.\n",
    "데이터의 스케일링, 타입 변환 등을 다시 한 번 확인하여 올바르게 제공되었는지 검토합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (877006, 4)\n",
      "Shape of X_test: (219252, 4)\n",
      "Shape of y_train: (877006, 2)\n",
      "Shape of y_test: (219252, 2)\n"
     ]
    },
    {
     "ename": "MissingDataError",
     "evalue": "exog contains inf or nans",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingDataError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 62\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of y_test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_test\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# SARIMAX 모델 설정 및 학습\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# PM25 예측 모델\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m model_pm25 \u001b[38;5;241m=\u001b[39m \u001b[43mSARIMAX\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPM25\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m results_pm25 \u001b[38;5;241m=\u001b[39m model_pm25\u001b[38;5;241m.\u001b[39mfit(disp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# PM10 예측 모델ß\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/statsmodels/tsa/statespace/sarimax.py:328\u001b[0m, in \u001b[0;36mSARIMAX.__init__\u001b[0;34m(self, endog, exog, order, seasonal_order, trend, measurement_error, time_varying_regression, mle_regression, simple_differencing, enforce_stationarity, enforce_invertibility, hamilton_representation, concentrate_scale, trend_offset, use_exact_diffuse, dates, freq, missing, validate_specification, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m),\n\u001b[1;32m    319\u001b[0m              seasonal_order\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), trend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m              measurement_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, time_varying_regression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    325\u001b[0m              freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, validate_specification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    326\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec \u001b[38;5;241m=\u001b[39m \u001b[43mSARIMAXSpecification\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseasonal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseasonal_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_stationarity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menforce_invertibility\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconcentrate_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcentrate_scale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_specification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_specification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_params \u001b[38;5;241m=\u001b[39m SARIMAXParams(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spec)\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# Save given orders\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/statsmodels/tsa/arima/specification.py:446\u001b[0m, in \u001b[0;36mSARIMAXSpecification.__init__\u001b[0;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[1;32m    441\u001b[0m         exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mc_[trend_data, exog]\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Create an underlying time series model, to handle endog / exog,\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;66;03m# especially validating shapes, retrieving names, and potentially\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# providing us with a time series index\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model \u001b[38;5;241m=\u001b[39m \u001b[43mTimeSeriesModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                              \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m faux_endog \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mendog\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/statsmodels/tsa/base/tsa_model.py:470\u001b[0m, in \u001b[0;36mTimeSeriesModel.__init__\u001b[0;34m(self, endog, exog, dates, freq, missing, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dates\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    469\u001b[0m ):\n\u001b[0;32m--> 470\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;66;03m# Date handling in indexes\u001b[39;00m\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_dates(dates, freq)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/statsmodels/base/model.py:270\u001b[0m, in \u001b[0;36mLikelihoodModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialize()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/statsmodels/base/model.py:95\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, endog, exog, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m missing \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     94\u001b[0m hasconst \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhasconst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m                              \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mk_constant\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexog\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/statsmodels/base/model.py:135\u001b[0m, in \u001b[0;36mModel._handle_data\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, endog, exog, missing, hasconst, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 135\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;66;03m# kwargs arrays could have changed, easier to just attach here\u001b[39;00m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m kwargs:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/statsmodels/base/data.py:675\u001b[0m, in \u001b[0;36mhandle_data\u001b[0;34m(endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     exog \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(exog)\n\u001b[1;32m    674\u001b[0m klass \u001b[38;5;241m=\u001b[39m handle_data_class_factory(endog, exog)\n\u001b[0;32m--> 675\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mklass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhasconst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhasconst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m             \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/statsmodels/base/data.py:88\u001b[0m, in \u001b[0;36mModelData.__init__\u001b[0;34m(self, endog, exog, missing, hasconst, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconst_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_constant \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhasconst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity()\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/statsmodels/base/data.py:134\u001b[0m, in \u001b[0;36mModelData._handle_constant\u001b[0;34m(self, hasconst)\u001b[0m\n\u001b[1;32m    132\u001b[0m exog_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(exog_max)\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingDataError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexog contains inf or nans\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    135\u001b[0m exog_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexog, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    136\u001b[0m const_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(exog_max \u001b[38;5;241m==\u001b[39m exog_min)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mMissingDataError\u001b[0m: exog contains inf or nans"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "# 파일 경로 설정\n",
    "file_21 = '/Users/hayden/Desktop/2021년전체측정소자료.csv'\n",
    "file_22 = '/Users/hayden/Desktop/2022년전체측정소자료.csv'\n",
    "file_23 = '/Users/hayden/Desktop/2023년전체측정소자료.csv'\n",
    "\n",
    "# reading each csv file as data frame\n",
    "df_21 = pd.read_csv(file_21)\n",
    "df_22 = pd.read_csv(file_22)\n",
    "df_23 = pd.read_csv(file_23)\n",
    "\n",
    "# list \n",
    "dfs = [df_21, df_22, df_23]\n",
    "\n",
    "# concat\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# 불필요한 열 제거\n",
    "df = df[~df['STTN_NM'].isin(['이동차', '부산항'])]\n",
    "df.drop(columns=['NO', 'NOX', 'STTN_NM'], inplace=True)\n",
    "\n",
    "# MinMaxScaler 사용\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = ['PM25', 'PM10', 'O3', 'CO', 'SO2', 'NO2']\n",
    "df[numeric_columns] = scaler.fit_transform(df[numeric_columns])\n",
    "\n",
    "# 데이터 타입 확인 및 변환\n",
    "df[numeric_columns] = df[numeric_columns].astype(float)\n",
    "# df['Year'] = df['Year'].astype(int)\n",
    "# df['Month'] = df['Month'].astype(int)\n",
    "# df['Hour'] = df['Hour'].astype(int)\n",
    "\n",
    "# 타겟 변수 설정 (예시로 PM25와 PM10 예측)\n",
    "target_columns = ['PM25', 'PM10']\n",
    "X = df.drop(columns=target_columns + ['MSR_DT'])  # 예측에 사용될 피처\n",
    "y = df[target_columns]  # 타겟 변수\n",
    "\n",
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 인덱스 확인 및 설정\n",
    "X_train.index = pd.to_datetime(df['MSR_DT'][X_train.index])\n",
    "X_test.index = pd.to_datetime(df['MSR_DT'][X_test.index])\n",
    "y_train.index = pd.to_datetime(df['MSR_DT'][y_train.index])\n",
    "y_test.index = pd.to_datetime(df['MSR_DT'][y_test.index])\n",
    "\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "print(f\"Shape of y_test: {y_test.shape}\")\n",
    "\n",
    "# SARIMAX 모델 설정 및 학습\n",
    "# PM25 예측 모델\n",
    "model_pm25 = SARIMAX(y_train['PM25'], exog=X_train, order=(1, 1, 1))\n",
    "results_pm25 = model_pm25.fit(disp=False)\n",
    "\n",
    "# PM10 예측 모델ß\n",
    "model_pm10 = SARIMAX(y_train['PM10'], exog=X_train, order=(1, 1, 1))\n",
    "results_pm10 = model_pm10.fit(disp=False)\n",
    "\n",
    "# 예측\n",
    "pred_pm25 = results_pm25.get_prediction(exog=X_test).predicted_mean\n",
    "pred_pm10 = results_pm10.get_prediction(exog=X_test).predicted_mean\n",
    "\n",
    "# 예측 결과를 데이터프레임으로 저장\n",
    "test_pred = pd.DataFrame({'test_PM25': y_test['PM25'], 'pred_PM25': pred_pm25,\n",
    "                          'test_PM10': y_test['PM10'], 'pred_PM10': pred_pm10}, index=y_test.index)\n",
    "\n",
    "print(test_pred.head())\n",
    "\n",
    "# 성능 평가\n",
    "mse_pm25 = mean_squared_error(y_test['PM25'], pred_pm25)\n",
    "mse_pm10 = mean_squared_error(y_test['PM10'], pred_pm10)\n",
    "\n",
    "print(f\"Mean Squared Error for PM25: {mse_pm25}\")\n",
    "print(f\"Mean Squared Error for PM10: {mse_pm10}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
